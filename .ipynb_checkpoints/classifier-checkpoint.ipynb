{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms as T\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../input/jovian-pytorch-z2g/Human protein atlas'\n",
    "\n",
    "TRAIN_DIR = DATA_DIR + '/train'                           \n",
    "TEST_DIR = DATA_DIR + '/test'                             \n",
    "\n",
    "TRAIN_CSV = DATA_DIR + '/train.csv'                       \n",
    "TEST_CSV = '../input/jovian-pytorch-z2g/submission.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(TRAIN_CSV)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0: 'Mitochondria',\n",
    "    1: 'Nuclear bodies',\n",
    "    2: 'Nucleoli',\n",
    "    3: 'Golgi apparatus',\n",
    "    4: 'Nucleoplasm',\n",
    "    5: 'Nucleoli fibrillar center',\n",
    "    6: 'Cytosol',\n",
    "    7: 'Plasma membrane',\n",
    "    8: 'Centrosome',\n",
    "    9: 'Nuclear speckles'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    target = torch.zeros(10)\n",
    "    for l in str(label).split(' '):\n",
    "        target[int(l)] = 1.\n",
    "    return target\n",
    "\n",
    "def decode_target(target, text_labels=False, threshold=0.5):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if (x >= threshold):\n",
    "            if text_labels:\n",
    "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
    "            else:\n",
    "                result.append(str(i))\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanProteinDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        img_id, img_label = row['Image'], row['Label']\n",
    "        img_fname = self.root_dir + \"/\" + str(img_id) + \".png\"\n",
    "        img = Image.open(img_fname)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, encode_label(img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.RandomCrop(256, padding=8, padding_mode='reflect'),\n",
    "    T.RandomHorizontalFlip(), \n",
    "    T.RandomRotation(10),\n",
    "    T.ToTensor(), \n",
    "#     T.RandomErasing(inplace=True)\n",
    "])\n",
    "\n",
    "valid_tfms = T.Compose([\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk = np.random.rand(len(data_df)) < 0.9\n",
    "\n",
    "train_df = data_df[msk].reset_index()\n",
    "val_df = data_df[~msk].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HumanProteinDataset(train_df, TRAIN_DIR, transform=train_tfms)\n",
    "val_ds = HumanProteinDataset(val_df, TRAIN_DIR, transform=valid_tfms)\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(img, target, invert=True):\n",
    "    if invert:\n",
    "        plt.imshow(1 - img.permute((1, 2, 0)))\n",
    "    else:\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "    print('Labels:', decode_target(target, text_labels=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample(*train_ds[1541])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, \n",
    "                      num_workers=3, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, \n",
    "                    num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl, invert=True):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        data = 1-images if invert else images\n",
    "        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_score(output, label, threshold=0.5, beta=1):\n",
    "    prob = output > threshold\n",
    "    label = label > threshold\n",
    "\n",
    "    TP = (prob & label).sum(1).float()\n",
    "    TN = ((~prob) & (~label)).sum(1).float()\n",
    "    FP = (prob & (~label)).sum(1).float()\n",
    "    FN = ((~prob) & label).sum(1).float()\n",
    "\n",
    "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
    "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
    "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
    "    return F2.mean(0)\n",
    "\n",
    "def focal_loss(inputs, targets):\n",
    "#     CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "#     print(inputs.size())\n",
    "    CE_loss = F.binary_cross_entropy(inputs, targets)\n",
    "    pt = torch.exp(-CE_loss)\n",
    "    F_loss = 1. * ((1-pt)**1.) * CE_loss\n",
    "    return F_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, targets = batch \n",
    "        out = self(images)                      \n",
    "#         loss = F.binary_cross_entropy(out, targets)\n",
    "        loss = focal_loss(out, targets)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, targets = batch \n",
    "        out = self(images)                           # Generate predictions\n",
    "#         loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n",
    "        print(out.size())\n",
    "        loss = focal_loss(out, targets)\n",
    "        score = F_score(out, targets)\n",
    "        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_scores = [x['val_score'] for x in outputs]\n",
    "        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinResnet(MultilabelImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.densenet121(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.classifier.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, 10)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return torch.sigmoid(self.network(xb))\n",
    "    \n",
    "    def freeze(self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = False\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad = True\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(ProteinResnet(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [evaluate(model, val_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
